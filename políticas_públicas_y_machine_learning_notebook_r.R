# -*- coding: utf-8 -*-
"""Políticas Públicas y Machine Learning - Notebook R.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1t3ZnWpRxjZZwSbjvvl7-EwBPdwLk7H_k

***UNaB***
#***Trabajo Práctico Integrador***
Materia **"Políticas Públicas y Machine Learning"**\
*Diplomatura en Análisis de Datos para el Desarrollo de Políticas Públicas*\
Universidad Nacional Guillermo Brown

***Docente:***\
Marianela Sarabia

***Integrantes:***\
Alejandro Blasco\
Diego Orainde\
Alfredo Rafael Díaz

# Documentación

*   Fuente: Datos correspondientes a los trabajadores formales del AMBA registrados en el Sistema Integrado Previsional Argentino (SIPA), incluyendo desagregación geográfica a nivel de radio censal y sector de actividad a dos dígitos y a nivel de letra (CLAE) https://datos.gob.ar/dataset/produccion-distribucion-empleo-formal-amba
*   Repositorio GIT: https://github.com/DiploDatosUNAB/PPyML-TPF-Blasco-Orainde-Diaz
*   Texto TPI: https://docs.google.com/document/d/1VHzNVM_oqZWIXRu-P9h2l299MbaJmtyF-FMtq6djJIM/edit
*   Versión .rmd:

# Análisis Exploratorio de Datos

## 0.Acciones Preliminares
"""

# NOTA: Es posible conectar a un entorno T4 GPU y aprovechar la capacidad de procesamiento para ML
# https://serverguy.com/comparison/cpu-vs-gpu-vs-tpu/
# https://saturncloud.io/blog/how-to-activate-gpu-computing-in-google-colab/
# https://bookdown.org/yshang/book/
# https://stackoverflow.com/questions/54595285/how-to-use-r-with-google-colaboratory
# https://colab.research.google.com/github/IRkernel/IRkernel/blob/master/example-notebooks/Display.ipynb

# PARÁMETROS

# Habilitar Análisis Geoespacial (sf)
SIG <- TRUE
# Habilitar Clasificación y Regresión (caret)
ML <- FALSE

# Clonación de datos del repositorio Git
system("git clone --single-branch --branch datos https://github.com/DiploDatosUNAB/PPyML-TPF-Blasco-Orainde-Diaz.git data")

# Agregado del archivo Empleo-AMBA.csv  a la notebook, que por tamaño no puede ser alojado en github
library(googledrive)
# URL del archivo compartido en Google Drive
drive_url <- "https://drive.google.com/file/d/1oIgB5CCFFGFjF0PaP1GykQyw0Dfyrd-Y/view?usp=sharing"
drive_id <- sub(".*/d/([^/]+)/.*", "\\1", drive_url)
drive_path <- sprintf("https://drive.google.com/uc?export=download&id=%s", drive_id)
download.file(drive_path, "/content/data/Empleo-AMBA.csv", mode = "wb")

# instalación condicional de librerías (solo instala si faltan)
# https://stackoverflow.com/questions/66869137/installing-r-packages-in-colab
# https://stackoverflow.com/questions/63594521/install-a-r-package-permanently-in-google-colab
instalar <- function(libreria) {
  if (!requireNamespace(libreria, quietly = TRUE)) {
    install.packages(libreria)
  }
}

# paquetes <- c("sf","gt","psych","skimr","caret")
# for (paquete in paquetes) {
#   instalar(paquete)
# }

# demora 5-10 segundos
instalar("kableExtra")

# demora 30-45 segundos
instalar("psych")

# demora demora 3-8 segundos
instalar("skimr")

# demora 5-7 minutos
if (ML) {
  instalar("caret")
}

# demora 7-12 minutos
if (SIG) {
  instalar("sf")
}

# carga condicional de librerías (solo carga si están instaladas)
cargar <- function(libreria) {
  if (requireNamespace(libreria, quietly = TRUE)) {
    library(libreria, character.only = TRUE)
  }
}

# carga de librerías a utilizar
library(lattice)    # graficación estadistica
library(ggplot2)    # graficación
library(readr)      # lectura de datos
library(cluster)    # clustering
library(dplyr)      # manipulación de df
library(skimr)      # estadísticas
library(stats)      # estadísticas
library(kableExtra) # tablas
library(psych)      # estadísticas
library(IRdisplay)  # display de notebook
library(stringr)    # cadenas de caracteres
cargar("caret")     # entrenamiento
cargar("sf")        # datos geoespaciales

"""## 1.Listado de Tablas

### 1.1.Empleo AMBA

#### 1.1.1.Tabla principal
"""

# Empleo AMBA
df <- read.csv("/content/data/Empleo-AMBA.csv", sep = ",", encoding = "UTF-8")
head(df, 5)

# dimensiones
cat("El DataFrame tiene", dim(df)[1], "observaciones y", dim(df)[2], "variables.")

"""#### Diccionario de datos"""

# diccionario de datos
descripciones <- c(
  "Identificador del radio censal",
  "Indicador de provincia",
  "Indicador de departamento",
  "Indicador de CLAE a dos dígitos de desagregación",
  "Indicador de CLAE a nivel de letra",
  "Cantidad de trabajadores en el radio censal para la desagregación de dos dígitos",
  "Cantidad de trabajadores hombres en el radio censal para la desagregación de dos dígitos",
  "Cantidad de trabajadoras mujeres en el radio censal para la desagregación de dos dígitos",
  "Salario medio de los trabajadores del radio censal para cada nivel de desagregación de actividad",
  "Salario medio de los trabajadores hombres del radio censal para cada nivel de desagregación de actividad",
  "Salario medio de los trabajadoras mujeres del radio censal para cada nivel de desagregación de actividad",
  "Salario mediano de los trabajadores del radio censal para cada nivel de desagregación de actividad",
  "Salario mediano de los trabajadores hombres del radio censal para cada nivel de desagregación de actividad",
  "Salario mediano de los trabajadoras mujeres del radio censal para cada nivel de desagregación de actividad",
  "Cantidad de personas que habitan en el radio censal según Censo 2010 (INDEC)",
  "Cantidad de viviendas en el radio censal según Censo 2010 (INDEC)"
)

diccionario <- data.frame(
  Clase = sapply(df, class),
  Descripción = descripciones
)

diccionario <- tibble::rownames_to_column(diccionario, "Variable")

diccionario

"""#### 1.1.2. Reducción a letra"""

# Empleo AMBA a letra
df_a_letra <- read.csv("/content/data/Empleo-AMBA-a-letra.csv", sep = ",", encoding = "UTF-8")
empleo_tipo <- df_a_letra
head(df_a_letra, 5)

# dimensiones
cat("El DataFrame tiene", dim(df_a_letra)[1], "observaciones y", dim(df_a_letra)[2], "variables.")

# lista de variables
print(attr(df_a_letra, "names"))

"""Esta tabla posee la misma información que la principal, pero los datos de distintos CLAE dentro de una categoría de actividad fueron unificados.

#### 1.1.3 Sin Desagregar
"""

# Empleo AMBA sin desagregar
df_sin_desagregar <- read.csv("/content/data/Empleo-AMBA-sin-desagregar.csv", sep = ",", encoding = "UTF-8")
empleo <- df_sin_desagregar
head(df_sin_desagregar, 5)

# dimensiones
cat("El DataFrame tiene", dim(df_sin_desagregar)[1], "observaciones y", dim(df_sin_desagregar)[2], "variables.")

# lista de variables
print(attr(df_sin_desagregar, "names"))

"""Esta tabla posee la misma información que la principal, pero sin desagregar por nomenclador de actividades.

### 1.2.Tablas Auxiliares

#### Actividades
"""

actividades <- read.csv("/content/data/actividades.csv", sep = ",", encoding = "UTF-8")
head(actividades, 5)

cat("El DataFrame tiene", dim(actividades)[1], "observaciones y", dim(actividades)[2], "variables.")

# Listado de actividades
print(unique(actividades$letra_desc))

# Cuadro de actividades x letra y clae
actividad_clae <- actividades |>
  group_by(letra_desc) |>
  summarize(CLAE = paste(clae2_desc, collapse = " - "))

tabla_html <- actividad_clae |>
  kable(format = "html") |>
  kable_styling()

  display_html(as.character(tabla_html))

"""#### Jurisdicciones"""

jurisdicciones <- read.csv("/content/data/jurisdicciones.csv", sep = ",", encoding = "UTF-8")
tail(jurisdicciones)

cat("El DataFrame tiene", dim(jurisdicciones)[1], "observaciones y", dim(jurisdicciones)[2], "variables.")

# Listado de departamentos
print(unique(jurisdicciones$departamento))

"""### 1.3.Radios Censales"""

# lectura de los polígonos de radios censales
if (SIG) {
  radios_censales <- sf::st_read("/content/data/Shapes/Shape AMBA.shp")
}

# Función para mostrar tablas con datos geoespaciales sin error
display_geo <- function(tabla, n = 10) {
  # Verificar que se haya proporcionado una tabla de datos
  if (!is.data.frame(tabla)) {
    stop("El argumento 'tabla' debe ser un data frame.")
  }

  tabla_kable <- kable(head(tabla, n), format = "html") |>
    kable_styling()
  tabla_html <- as.character(tabla_kable)
  display_html(tabla_html)
}

if (SIG) {
  display_geo(radios_censales, 10)
}

# graficación de radios censales
if (SIG) {
  ggplot() +
    geom_sf(data = radios_censales) +
    labs(title = "Radios Censales en Área Metropolitana de Buenos Aires")
}

if (SIG) {
  radios_caba <- subset(radios_censales, grepl("_", CO_FRAC_RA))
}

# graficación de radios censales
if (SIG) {
  ggplot() +
    geom_sf(data = radios_caba) +
    labs(title = "Radios Censales en Ciudad Autónoma de Buenos Aires")
}

"""## Transformaciones

Debido a que algunas operaciones de machine learning superaban los umbrales de memoria y procesamiento disponibles, y otros arrojaban errores y advertencias, se probó unificando los datos de diferentes radios censales correspondientes a un mismo departamento.

### Agrupar por jurisdicción
"""

# generar columnas de remuneración total
# agrupar por provincia y departamento
# dividir remuneración total por cantidad de trabajadores para obtener media departamental
# no se pudo realizar lo mismo para la mediana
df_x_departamento <- df |>
  mutate(
    Remuneracion_total = Remuneracion_media * Cantidad_trabajadores,
    Remuneracion_total_Hombres = Remuneracion_media_Hombres * Cantidad_trabajadores_Hombres,
    Remuneracion_total_Mujeres = Remuneracion_media_Mujeres * Cantidad_trabajadores_Mujeres
  ) |>
  group_by(provincia_id, departamento_id) |>
  summarise(
    Cantidad_trabajadores = sum(Cantidad_trabajadores),
    Cantidad_trabajadores_Hombres = sum(Cantidad_trabajadores_Hombres),
    Cantidad_trabajadores_Mujeres = sum(Cantidad_trabajadores_Mujeres),
    Remuneracion_media = sum(Remuneracion_total) / sum(Cantidad_trabajadores),
    Remuneracion_media_Hombres = sum(Remuneracion_total_Hombres) / sum(Cantidad_trabajadores_Hombres),
    Remuneracion_media_Mujeres = sum(Remuneracion_total_Mujeres) / sum(Cantidad_trabajadores_Mujeres),
    Poblacion_radio = sum(Poblacion_radio),
    Viviendas_radio = sum(Viviendas_radio)
  )

head(df_x_departamento)

# dimensiones
cat("El DataFrame tiene", dim(df_x_departamento)[1], "observaciones y", dim(df_x_departamento)[2], "variables.")

# realiza la misma operación para la tabla no desagregada por actividad
df_sin_des_x_dep <- df_sin_desagregar |>
  mutate(
    Remuneracion_total = Remuneracion_media * Cantidad_trabajadores,
    Remuneracion_total_Hombres = Remuneracion_media_Hombres * Cantidad_trabajadores_Hombres,
    Remuneracion_total_Mujeres = Remuneracion_media_Mujeres * Cantidad_trabajadores_Mujeres
  ) |>
  group_by(provincia_id, departamento_id) |>
  summarise(
    Cantidad_trabajadores = sum(Cantidad_trabajadores),
    Cantidad_trabajadores_Hombres = sum(Cantidad_trabajadores_Hombres),
    Cantidad_trabajadores_Mujeres = sum(Cantidad_trabajadores_Mujeres),
    Remuneracion_media = sum(Remuneracion_total) / sum(Cantidad_trabajadores),
    Remuneracion_media_Hombres = sum(Remuneracion_total_Hombres) / sum(Cantidad_trabajadores_Hombres),
    Remuneracion_media_Mujeres = sum(Remuneracion_total_Mujeres) / sum(Cantidad_trabajadores_Mujeres),
    Poblacion_radio = sum(Poblacion_radio),
    Viviendas_radio = sum(Viviendas_radio)
  )

head(df_sin_des_x_dep)

# dimensiones
cat("El DataFrame tiene", dim(df_sin_des_x_dep)[1], "observaciones y", dim(df_sin_des_x_dep)[2], "variables.")

# Cantidad de departamentos
cat("Cantidad de departamentos de la df:", length(unique(df$departamento_id)))

# Cantidad de registros por departamento
registros_depto <- as.data.frame(table(df$departamento_id))
colnames(registros_depto) <- c("departamento_id", "registros")
registros_depto <- registros_depto |> arrange(registros)

registros_depto

df_6329 <- df[df$departamento_id == 6329, ]
write.csv2(df_6329, "/content/data/df_gral_las_heras_6329.csv", row.names = FALSE)

df_sin_des_x_dep[df_sin_des_x_dep$departamento_id == 6329, ]

"""### Polígonos por jurisdicción

Se busca unificar los poligonos de radios censales para crear polígonos por departamento
"""

# df con datos de radios censales, departamento y provincia
radio_depto <- df_sin_desagregar[, c("LINK", "provincia_id", "departamento_id")]

tail(radio_depto)

# Realizar un left join entre radios censales y radio_depto
radios_censales_con_depto <- merge(radios_censales, radio_depto, by.x = "CO_FRAC_RA", by.y = "LINK", all.x = TRUE)

display_geo(radios_censales_con_depto)

# Verificar si existen valores que no tengan correspondencia
cantidad_na <- sum(is.na(radios_censales_con_depto$departamento_id))
print(paste("Cantidad de valores NA en departamento_id:", cantidad_na))

"""Existen múltiples NA, por lo que deben existir diferencias entre los datos o formato de la tabla de polígonos (radios censales), y las del df (radio_depto)"""

# Contar valores únicos en la columna CO_FRAC_RA de radios_censales
valores_unicos_CO_FRAC_RA <- length(unique(radios_censales$CO_FRAC_RA))
print(paste("Valores únicos en CO_FRAC_RA:", valores_unicos_CO_FRAC_RA))

# Contar valores únicos en la columna LINK de radio_depto
valores_unicos_LINK <- length(unique(radio_depto$LINK))
print(paste("Valores únicos en LINK:", valores_unicos_LINK))

# Verificar si hay valores en CO_FRAC_RA que no están en LINK
missing_values <- setdiff(radios_censales$CO_FRAC_RA, radio_depto$LINK)

# Verificar si hay valores en LINK que no están en CO_FRAC_RA
missing_values_reverse <- setdiff(radio_depto$LINK, radios_censales$CO_FRAC_RA)

# Imprimir los resultados
print("Valores en CO_FRAC_RA que no están en LINK:")
print(missing_values)

print("Valores en LINK que no están en CO_FRAC_RA:")
print(missing_values_reverse)

"""No se puede utilizar el left join para obtener el id del departamento, debido a que los valores de radios en la df y en los polígonos no coinciden. Se prueba extrayendo los datos de los id de radios censales."""

# Filtrar los datos de la tabla jurisdicciones para provincia "CABA"
id_comunas <- jurisdicciones |>
  filter(provincia == "CABA") |>
  select(id = departamento_id, comuna = departamento) |>
  mutate(comuna = as.integer(sub("Comuna ", "", comuna)))

head(id_comunas)

# Crear un subset con los poligonos de CABA
radios_caba <- subset(radios_censales, grepl("_", CO_FRAC_RA))

# Añadir columnas provincia_id y departamento_id
radios_caba <- radios_caba |>
  mutate(provincia_id = 2,
         departamento_id = as.integer(str_extract(CO_FRAC_RA, "^[0-9]+"))) |>
  select(CO_FRAC_RA, provincia_id, departamento_id, geometry)

# Reemplazar el valor que hay almacenado en departamento_id (nº de comuna)
# por el id que figura en id_comuna
radios_caba <- radios_caba |>
  mutate(departamento_id = id_comunas$id[match(as.character(departamento_id), id_comunas$comuna)])

display_geo(radios_caba)

# Crear un subset con los poligonos de PBA
radios_pba <- subset(radios_censales, !grepl("_", CO_FRAC_RA))

# Añadir columnas provincia_id y departamento_id
radios_pba <- radios_pba |>
  mutate(provincia_id = 6,
         departamento_id = as.integer(str_sub(CO_FRAC_RA, 2, 5))) |>
  select(CO_FRAC_RA, provincia_id, departamento_id, geometry)

display_geo(radios_pba)

# Unificar radios_caba y radios_pba
radios_censales_con_depto <- rbind(radios_caba, radios_pba)

# https://gis.stackexchange.com/questions/63577/joining-polygons-in-r
# https://r-spatial.github.io/sf/reference/geos_combine.html
# https://gis.stackexchange.com/questions/447288/the-combination-of-sfst-union-and-sfst-transform-turns-a-valid-geometry-into
# https://stackoverflow.com/questions/49354393/r-how-do-i-merge-polygon-features-in-a-shapefile-with-many-polygons-reproducib

# Agrupar por provincia_id y departamento_id y unificar los polígonos
if (SIG) {
departamentos <- radios_censales_con_depto |>
  # filter(departamento_id == 2007) |>
  group_by(provincia_id, departamento_id) |>
  summarise(geometry = sf::st_union(geometry))
}

"""Al parecer la unificación de polígonos no genera resultados perfectos."""

# Asegura que todos son multipoligonos
if (SIG) {
departamentos <- departamentos |>
  filter(st_geometry_type(geometry) != "POINT")
}

# Graficación de departamentos
if (SIG) {
  ggplot() +
    geom_sf(data = departamentos) +
    labs(title = "Departamentos en Área Metropolitana de Buenos Aires")
}

# graficación de barrios
if (SIG) {
  barrios_caba <- subset(departamentos, provincia_id == 2)
  ggplot() +
    geom_sf(data = barrios_caba) +
    labs(title = "Barrios en Ciudad Autónoma de Buenos Aires")
}

"""## Descripción

Para la descripción y análisis se generaron alias de las tablas principales:

*   Empleo AMBA --> `df`
*   Empleo AMBA a Letra --> `df_a_letra` --> `empleo_tipo`
*   Empleo AMBA sin desagregar --> `df_sin_desagregar` --> `empleo`
*   Empleo AMBA x departamento --> `df_x_departamento`
*   Empleo AMBA sin desagregar x departamento --> `df_sin_des_x_dep`
"""

# Función para crear una tabla con kable display html

display_kable <- function(tabla) {
  tabla_kable <- tabla |>
    kable(format = "html") |>
    kable_styling(full_width = FALSE)

  # Mostrar la tabla HTML
  display_html(as.character(tabla_kable))
}

# Descripción de Empleo AMBA sin desagregar
display_kable(summary(empleo))

# Descripción de Empleo AMBA a Letra
display_kable(summary(empleo_tipo))

# Descripción de Empleo AMBA sin desagregar x departamento
display_kable(summary(df_sin_des_x_dep))

hist(empleo$Remuneracion_media_Hombres, breaks = 1000,
     col='blue',
     main='histograma salario_medio',
     xlab='salario',
     ylab='Frequency')

empleo_means <- aggregate(empleo_tipo$Remuneracion_media,
                        list(empleo_tipo$letra),
                        mean)
empleo_means

filtrado <- empleo_tipo|>
  filter(Remuneracion_media_Hombres < 3000000, Remuneracion_media_Mujeres < 2000000)

ggplot(filtrado, aes(Remuneracion_media_Hombres,
                        Remuneracion_media_Mujeres)
       ) + geom_point(aes(col=letra), size=3)

filtrado2 <- empleo_tipo|>
  filter(Remuneracion_media_Hombres < 500000, Remuneracion_media_Mujeres < 500000)

ggplot(filtrado2, aes(Remuneracion_media_Hombres,
                        Remuneracion_media_Mujeres)
       ) + geom_point(aes(col=letra), size=3)

#boxplots comparados
boxplot(filtrado2$Remuneracion_media_Mujeres ~ filtrado2$letra,
        col = 1:3)
points(x = 1:nrow(empleo_means),
       y = empleo_means$x,
       pch = 16,
       col = "white")
text(x = 1:nrow(empleo_means),
     y = empleo_means$x + 1.2,
     labels = round(empleo_means$x, 2),
     col = "white")

plot(empleo_tipo$Remuneracion_media_Hombres, empleo_tipo$Remuneracion_media_Mujeres,
     col='steelblue',
     main='Scatterplot',
     xlab='Media hombres',
     ylab='Media mujeres',
     pch=19)

empleo_tipo2 <- na.omit(filtrado)

empleoCluster2 <- kmeans(filtrado[,9:10], center=2, iter.max=10, nstart=20)
empleoCluster2

empleoCluster3 <- kmeans(filtrado[,9:10], center=3, iter.max=10, nstart=20)
empleoCluster3

empleoCluster15 <- kmeans(filtrado[,9:10], center=15, iter.max=10, nstart=20)
empleoCluster15

table(empleoCluster15$cluster, filtrado$letra)
clusplot(filtrado, empleoCluster15$cluster, color=T, shade=T, labels=0, lines=0)

# INTERRUPCIÓN. ELIMINAR O COMENTAR SEGÚN SEA NECESARIO
stop("Detención manual del código")

# Para abordar estos warnings, podrías considerar ajustar el número de centroides
# que estás probando (center) o modificar otros parámetros del algoritmo k-means,
# como nstart, que controla el número de inicializaciones aleatorias que se ejecutan
# para encontrar el mejor resultado. También podrías evaluar la estructura de tus
# datos para determinar si el número de centroides elegido tiene sentido desde
# un punto de vista de negocio o análisis de datos.

tot.withinss <- vector(mode="character", length=10)
for (i in 1:15){
  empleoCluster <- kmeans(filtrado[,9:10], center=i, nstart=20)
  tot.withinss[i] <- empleoCluster$tot.withinss
}

plot(1:15, tot.withinss, type="b", pch=19)

xyplot(Remuneracion_media_Hombres ~ Remuneracion_media_Mujeres,
       data = filtrado,
       type = c("p", "g", "smooth"),
       xlab = "Remuneracion_media_Hombres",
       ylab = "Remuneracion_media_Mujeres)")

xyplot(Remuneracion_media_Hombres ~ Remuneracion_media_Mujeres | letra,
       group = letra,
       data = filtrado,
       auto.key = TRUE,
       type = c("p", "smooth"),
       scales= "free")

set.seed(001)
intrain <- createDataPartition(y = filtrado$letra,
                               p= 0.7, list = FALSE)

training <- filtrado[intrain,] # nuevo dataset
testing <- filtrado[-intrain,] # nuevo dataset
dim(training)
dim(testing)

skimmed <- skim(training)
# skimmed[, c(1:15)]
summary(skimmed)[1:15]

x = training[, 9:10]
y = training$letra
x_test = testing[9:10]
y_test = testing$letra

trctrl1 <- trainControl(method =
                          "LOOCV", number = 10)

trctrl2 <- trainControl(method =
                          "repeatedcv", number = 10, repeats = 3)

# Acá muere x RAM
# knn_fit1 <- train(letra ~., data = training, method = "knn",
#                   trControl =trctrl1,
#                   tuneLength = 10)

# knn_fit2 <- train(letra ~., data = training, method = "knn",
#                   trControl =trctrl2,
#                   preProcess = c("center", "scale"),
#                   tuneLength = 10)



